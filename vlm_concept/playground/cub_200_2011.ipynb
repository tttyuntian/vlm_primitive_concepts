{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f1226ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f097e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "258730b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"../../data/CUB_200_2011\"\n",
    "\n",
    "# Load image data\n",
    "images = pd.read_csv(\n",
    "    os.path.join(data_root, \"CUB_200_2011\", \"images.txt\"),\n",
    "    sep=\" \", names=[\"image_id\", \"filepath\"],\n",
    ")\n",
    "image_class_labels = pd.read_csv(\n",
    "    os.path.join(data_root, \"CUB_200_2011\", \"image_class_labels.txt\"),\n",
    "    sep=\" \", names=[\"image_id\", \"class_id\"],\n",
    ")\n",
    "train_test_split = pd.read_csv(\n",
    "    os.path.join(data_root, \"CUB_200_2011\", \"train_test_split.txt\"),\n",
    "    sep=\" \", names=[\"image_id\", \"is_training_image\"],\n",
    ")\n",
    "classes = pd.read_csv(\n",
    "    os.path.join(data_root, \"CUB_200_2011\", \"classes.txt\"),\n",
    "    sep=\" \", names=[\"class_id\", \"class_name\"],\n",
    ")\n",
    "\n",
    "data = images.merge(image_class_labels, on=\"image_id\")\n",
    "data = data.merge(train_test_split, on=\"image_id\")\n",
    "data = data.merge(classes, on=\"class_id\")\n",
    "data = data[data.is_training_image==0]\n",
    "data[\"class_name\"] = [class_name.split(\".\")[1].lower().replace(\"_\", \" \") for class_name in data.class_name]\n",
    "\n",
    "# Load attribute data\n",
    "image_attribute_labels = pd.read_csv(\n",
    "    os.path.join(data_root, \"CUB_200_2011\", \"attributes\", \"image_attribute_labels.txt\"),\n",
    "    sep=\" \", names=[\"image_id\", \"attribute_id\", \"is_present\", \"certainty_id\", \"time\"],\n",
    ")\n",
    "attributes = pd.read_csv(\n",
    "    os.path.join(data_root, \"CUB_200_2011\", \"attributes\", \"attributes.txt\"),\n",
    "    sep=\" \", names=[\"attribute_id\", \"attribute_name\"]\n",
    ")\n",
    "attributes_info = [attr.split(\"::\") for attr in attributes.attribute_name]\n",
    "attributes_info = np.array([[attr.replace(\"_\", \" \"), label.replace(\"_\", \" \")] for attr, label in attributes_info])\n",
    "attributes[\"attribute_template\"] = attributes_info[:, 0]\n",
    "attributes[\"attribute_label\"] = attributes_info[:, 1]\n",
    "attributes = image_attribute_labels.merge(attributes, on=\"attribute_id\")\n",
    "unique_attributes = attributes.attribute_template.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a68f14",
   "metadata": {},
   "source": [
    "# CUB Concept Classificatin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "33c9ee71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1/1 [00:12<00:00, 12.05s/it]\n"
     ]
    }
   ],
   "source": [
    "# Zero-shot concept classification - 312 retrieval task\n",
    "topk = 1\n",
    "\n",
    "image_id_list, class_id_list, attribute_list, certainty_list = [],[],[],[]\n",
    "label_value_list, label_rank_list, pred_list, label_list = [],[],[],[]\n",
    "#for row_id in tqdm(range(len(data))):\n",
    "for row_id in tqdm(range(1)):\n",
    "    # Prepare image inputs\n",
    "    image_id, class_id, image_name = data.iloc[row_id][[\"image_id\", \"class_id\", \"filepath\"]]\n",
    "    image_path = os.path.join(data_root, \"CUB_200_2011\", \"images\", image_name)\n",
    "    image_input = preprocess(Image.open(image_path)).unsqueeze(0).to(device)\n",
    "    image_attributes = attributes[attributes.image_id==image_id]\n",
    "    \n",
    "    num_presented_attributes = 0\n",
    "    for uni_attr in unique_attributes:\n",
    "        curr_attr_df = image_attributes[image_attributes.attribute_template==uni_attr]\n",
    "        \n",
    "        if any(curr_attr_df.is_present):\n",
    "            # Only evaluate when an attribute is presented in the image\n",
    "            num_presented_attributes += 1\n",
    "            curr_attr_label = np.where(curr_attr_df.is_present)[0][0]\n",
    "            \n",
    "            # Prepare text inputs\n",
    "            text_inputs_raw = [\n",
    "                \"a photo of bird whose {} is {}\".format(attr.replace(\"has \", \"\"), label)\n",
    "                for attr, label in zip(curr_attr_df[\"attribute_template\"], curr_attr_df[\"attribute_label\"])\n",
    "            ]\n",
    "\n",
    "            # Multiclass concept classification\n",
    "            # Calculate features\n",
    "            text_inputs = clip.tokenize(text_inputs_raw).to(device)\n",
    "            with torch.no_grad():\n",
    "                image_features = model.encode_image(image_input)\n",
    "                text_features = model.encode_text(text_inputs)\n",
    "\n",
    "            # Pick k most similar labels for the image\n",
    "            image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "            text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "            similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "            values, indices = similarity[0].sort(descending=True)\n",
    "            pred = indices[0].item()\n",
    "            label_value = similarity[0][curr_attr_label].item()\n",
    "            label_rank = (indices==curr_attr_label).nonzero()[0][0].item() + 1  # Index to 1\n",
    "            certainty = curr_attr_df.certainty_id.mean()\n",
    "            \n",
    "            image_id_list.append(image_id)\n",
    "            class_id_list.append(class_id)\n",
    "            attribute_list.append(uni_attr)\n",
    "            label_value_list.append(label_value)\n",
    "            label_rank_list.append(label_rank)\n",
    "            pred_list.append(pred)\n",
    "            label_list.append(curr_attr_label)\n",
    "            certainty_list.append(certainty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "1cd1e801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>class_id</th>\n",
       "      <th>attribute</th>\n",
       "      <th>pred</th>\n",
       "      <th>label</th>\n",
       "      <th>label_value</th>\n",
       "      <th>label_rank</th>\n",
       "      <th>certainty_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>has bill shape</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.766961</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>has head pattern</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.121434</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>has throat color</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>7</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>has eye color</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125507</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>has bill length</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.271769</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>has forehead color</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0.152225</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>has nape color</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>0.055571</td>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>has size</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.171008</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>has shape</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.098761</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>has primary color</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>0.037261</td>\n",
       "      <td>11</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>has bill color</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0.083975</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>has crown color</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>0.027634</td>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_id  class_id           attribute  pred  label  label_value  \\\n",
       "0          1         1      has bill shape     4      4     0.766961   \n",
       "1          1         1    has head pattern     8      3     0.121434   \n",
       "2          1         1    has throat color     7     14     0.053571   \n",
       "3          1         1       has eye color     4      1     0.125507   \n",
       "4          1         1     has bill length     0      1     0.271769   \n",
       "5          1         1  has forehead color    12     12     0.152225   \n",
       "6          1         1      has nape color    12     14     0.055571   \n",
       "7          1         1            has size     3      0     0.171008   \n",
       "8          1         1           has shape     5      2     0.098761   \n",
       "9          1         1   has primary color     5     14     0.037261   \n",
       "10         1         1      has bill color     7     14     0.083975   \n",
       "11         1         1     has crown color    12     14     0.027634   \n",
       "\n",
       "    label_rank  certainty_id  \n",
       "0            1           3.0  \n",
       "1            2           3.0  \n",
       "2            7           4.0  \n",
       "3            2           4.0  \n",
       "4            3           4.0  \n",
       "5            1           4.0  \n",
       "6            8           4.0  \n",
       "7            4           2.0  \n",
       "8            3           2.0  \n",
       "9           11           3.0  \n",
       "10           6           4.0  \n",
       "11           9           4.0  "
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"image_id\": image_id_list,\n",
    "        \"class_id\": class_id_list,\n",
    "        \"attribute\": attribute_list,\n",
    "        \"pred\": pred_list,\n",
    "        \"label\": label_list,\n",
    "        \"label_value\": label_value_list,\n",
    "        \"label_rank\": label_rank_list,\n",
    "        \"certainty_id\": certainty_list,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53ec53e",
   "metadata": {},
   "source": [
    "# CUB Concept classification - to-be-removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1465f11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-shot concept classification - 312 retrieval task\n",
    "topk = 1\n",
    "\n",
    "image_id_list, class_id_list, attribute_id_list, certainty_id_list = [],[],[],[]\n",
    "value_list, pred_list, label_list = [],[],[]\n",
    "#for row_id in tqdm(range(len(data))):\n",
    "for row_id in tqdm(range(2)):\n",
    "    # Prepare image inputs\n",
    "    image_id, class_id, image_name = data.iloc[row_id][[\"image_id\", \"class_id\", \"filepath\"]]\n",
    "    image_path = os.path.join(data_root, \"CUB_200_2011\", \"images\", image_name)\n",
    "    image_input = preprocess(Image.open(image_path)).unsqueeze(0).to(device)\n",
    "    image_attributes = attributes[attributes.image_id==image_id]\n",
    "\n",
    "    # Prepare text inputs\n",
    "    text_inputs_raw = [\n",
    "        [\n",
    "            \"a photo of bird whose {} is not {}\".format(attr.replace(\"has \", \"\"), label),\n",
    "            \"a photo of bird whose {} is {}\".format(attr.replace(\"has \", \"\"), label),\n",
    "        ]\n",
    "        for attr, label in zip(attributes[\"attribute_template\"], attributes[\"attribute_label\"])\n",
    "    ]\n",
    "\n",
    "    curr_value, curr_pred = [],[]\n",
    "    for text in text_inputs_raw:\n",
    "        # Binary concept classification\n",
    "        # Calculate features\n",
    "        text_inputs = clip.tokenize(text)\n",
    "        with torch.no_grad():\n",
    "            image_features = model.encode_image(image_input)\n",
    "            text_features = model.encode_text(text_inputs)\n",
    "\n",
    "        # Pick k most similar labels for the image\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "        similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "        value, pred = similarity[0].topk(topk)\n",
    "        curr_value.append(value.item())\n",
    "        curr_pred.append(pred.item())\n",
    "    \n",
    "    image_id_list.append([image_id] * len(text_inputs_raw))\n",
    "    class_id_list.append([class_id] * len(text_inputs_raw))\n",
    "    attribute_id_list.append(np.arange(1, len(text_inputs_raw)+1))\n",
    "    value_list.append(curr_value)\n",
    "    pred_list.append(curr_pred)\n",
    "    label_list.append(image_attributes.is_present.to_numpy())\n",
    "    certainty_id_list.append(image_attributes.certainty_id.to_numpy())\n",
    "    \n",
    "    \"\"\"\n",
    "    # Zero-shot concept classifcation - Output\n",
    "    print(\"Top predictions:\\n\")\n",
    "    for text, value, pred in zip(text_inputs_raw, value_list, pred_list):\n",
    "        print(f\"{100 * value:6.2f}: {text[pred]}\")\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331553ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"image_id\": np.array(image_id_list).flatten(),\n",
    "        \"class_id\": np.array(class_id_list).flatten(),\n",
    "        \"attribute_id\": np.array(attribute_id_list).flatten(),\n",
    "        \"value\": np.array(value_list).flatten(),\n",
    "        \"pred\": np.array(pred_list).flatten(),\n",
    "        \"label\": np.array(label_list).flatten(),\n",
    "        \"certainty_id\": np.array(certainty_id_list).flatten(),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c34e27",
   "metadata": {},
   "source": [
    "# CUB Class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "acd2ffde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1/1 [00:14<00:00, 14.80s/it]\n"
     ]
    }
   ],
   "source": [
    "# Zero-shot bird species classfication\n",
    "topk = 1\n",
    "\n",
    "label = data.class_id\n",
    "image_id_list, value_list, pred_list = [],[],[]\n",
    "\n",
    "# Prepare text inputs\n",
    "text_inputs_raw = [f\"the bird is {class_name}\" for class_name in data.class_name.unique()]\n",
    "text_inputs = torch.cat([clip.tokenize(text) for text in text_inputs_raw]).to(device)\n",
    "\n",
    "#for row_id in tqdm(range(len(data))):\n",
    "for row_id in tqdm(range(2)):\n",
    "    # Prepare image inputs\n",
    "    image_id, image_name = data.iloc[row_id][[\"image_id\", \"filepath\"]]\n",
    "    image_path = os.path.join(data_root, \"CUB_200_2011\", \"images\", image_name)\n",
    "    image_input = preprocess(Image.open(image_path)).unsqueeze(0).to(device)\n",
    "\n",
    "    # Calculate featuress\n",
    "    with torch.no_grad():\n",
    "        image_features = model.encode_image(image_input)\n",
    "        text_features = model.encode_text(text_inputs)\n",
    "\n",
    "    # Pick k most similar labels for the image\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "    similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "    value, pred = similarity[0].topk(topk)\n",
    "\n",
    "    image_id_list.append(image_id)\n",
    "    value_list.append(value.item())\n",
    "    pred_list.append(pred.item())\n",
    "\n",
    "pred_list = np.array(pred_list) + 1  # Shift predictions by 1 to align with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "58f6dbfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>value</th>\n",
       "      <th>pred</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.64262</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id    value  pred  label\n",
       "0         1  0.64262     1      1"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"image_id\": np.array(image_id_list).flatten(),\n",
    "        \"value\": np.array(value_list).flatten(),\n",
    "        \"pred\": np.array(pred_list).flatten(),\n",
    "        \"label\": np.array(label[:2]).flatten(),\n",
    "    }\n",
    ")\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlm_concept_dev",
   "language": "python",
   "name": "vlm_concept_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
